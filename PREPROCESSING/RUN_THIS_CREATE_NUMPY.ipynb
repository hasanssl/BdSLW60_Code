{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we will import all the dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 10:52:20.707698: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-30 10:52:20.741705: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 10:52:20.741762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 10:52:20.742684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 10:52:20.748338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-30 10:52:21.537926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "# from matplotlib import pyplot as plt\n",
    "# import time\n",
    "import mediapipe as mp\n",
    "# import re\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data_folder = \"../VideoData\"\n",
    "bds_folder = \"../BdSLW60\"\n",
    "numerical_data_path='../NumericalData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "# mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_landmarks(image, results):\n",
    "#     mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "#     mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "#     mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "#     mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_styled_landmarks(image, results):\n",
    "#     # Draw face connections\n",
    "#     mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "#                              mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "#                              mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "#                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract Keypoint Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3) \n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A NumPy array with all values set to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_numeric(s):\n",
    "#     try:\n",
    "#         float(s)\n",
    "#         return True\n",
    "#     except ValueError:\n",
    "#         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Open the JSON file\n",
    "datas = []\n",
    "word_lists = os.listdir(bds_folder)\n",
    "for word in word_lists:\n",
    "    if word.endswith('.pdf') or word.endswith('.xlsx') or word.endswith('.txt'):\n",
    "        pass \n",
    "    else:\n",
    "        with open(f'{bds_folder}/{word}/output1.json', 'r') as file:\n",
    "            # Step 3: Parse the JSON data into a Python data structure\n",
    "            datas.append(json.load(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# #Read JSON files\n",
    "\n",
    "# JSON_PATH = '../Preprocessing/output1.json'\n",
    "\n",
    "# JSON_file = open(JSON_PATH)\n",
    "\n",
    "# JSON_DATA = json.load(JSON_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a folder named 'VideoData' in the code directory\n",
    "\n",
    "os.makedirs(video_data_folder, exist_ok=True)\n",
    "\n",
    "# Path to the folder containing your videos\n",
    "\n",
    "\n",
    "# Iterate through each subfolder in the BdSLW60 folder\n",
    "for subfolder_name in os.listdir(bds_folder):\n",
    "    subfolder_path = os.path.join(bds_folder, subfolder_name)\n",
    "\n",
    "    # Check if the item in the BdSLW60 folder is a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Iterate through video files in the current subfolder\n",
    "        for video_file_name in os.listdir(subfolder_path):\n",
    "            video_file_path = os.path.join(subfolder_path, video_file_name)\n",
    "\n",
    "            # Check if the item is a file and ends with \".mp4\"\n",
    "            if os.path.isfile(video_file_path) and video_file_name.endswith(\".mp4\"):\n",
    "                # Extract the word from the filename (assuming it's always the second character)\n",
    "                w_idx = 0\n",
    "\n",
    "                f_idx = 0\n",
    "                for idx in range(0,len(video_file_name)):\n",
    "                    if video_file_name[idx]=='W':\n",
    "                        w_idx = idx \n",
    "                        break\n",
    "                \n",
    "                for idx in range(0,len(video_file_name)):\n",
    "                    if video_file_name[idx]=='F':\n",
    "                        f_idx = idx \n",
    "                        break\n",
    "                word = video_file_name[w_idx+1:f_idx]\n",
    "                # Create a corresponding folder in 'VideoData' based on the word\n",
    "                video_data_subfolder = os.path.join(video_data_folder, f\"W{word}\")\n",
    "                os.makedirs(video_data_subfolder, exist_ok=True)\n",
    "\n",
    "                # Copy the video file to the corresponding folder in 'VideoData'\n",
    "                shutil.copy(video_file_path, os.path.join(video_data_subfolder, video_file_name))\n",
    "\n",
    "print(\"Video files copied successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the folder containing the video files\n",
    "#VIDEO_FOLDER = 'VideoData'\n",
    "#all_words = os.listdir(VIDEO_FOLDER)\n",
    "# Actions that we try to detect\n",
    "#actions = np.array(all_words)\n",
    "\n",
    "# Function to process a video file\n",
    "def process_video(video_path, fileName_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # print(video_path)\n",
    "    sequence_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sequence = 1\n",
    "    # Set mediapipe model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        # for sequence in range(no_sequences):\n",
    "            for frame_num in range(sequence_length):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Make de8tections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "                # Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(fileName_path, str(sequence))\n",
    "                np.save(npy_path, keypoints)\n",
    "                sequence += 1\n",
    "                # Break gracefully\n",
    "                #if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                #    break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNpy(source_folder, fileName_path, fileName):\n",
    "    video_path = os.path.join(source_folder, fileName+'.mp4')\n",
    "    print(video_path)\n",
    "    process_video(video_path, fileName_path)\n",
    "    print('Npy creation finished for file: '+fileName)\n",
    "    # sequence_path = os.path.join(f'Data/{action}',fileName)\n",
    "    # cam = cv2.VideoCapture(video_path)\n",
    "    # fps = cam.get(cv2.CAP_PROP_FPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "max_frame = 0\n",
    "min_frame = 99999980\n",
    "user = ''\n",
    "\n",
    "max_start = 0\n",
    "max_end = 0\n",
    "max_ind = 0\n",
    "\n",
    "\n",
    "min_start = 0\n",
    "min_end = 0\n",
    "min_ind = 0\n",
    "\n",
    "diff = 0\n",
    "\n",
    "total_frameCount= 0\n",
    "total_trails=0\n",
    "\n",
    "training_left_trials=0\n",
    "training_right_trials=0\n",
    "\n",
    "test_right_trials =0\n",
    "test_left_trials=0\n",
    "\n",
    "\n",
    "testUser = {'U4','U8'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max frame is 164 U17W355F 5 878 1041\n",
      "Min frame is 9 U8W216F 10 772 780\n",
      "No of trials:  9307\n",
      "Avg frames per trial:  44.20027935962179\n",
      "Total Training instances:  8031  Right Hand:  6530  Left Hand:  1501\n",
      "Total Test instances:  1276  Right Hand:  1143  Left Hand:  133\n"
     ]
    }
   ],
   "source": [
    "for data in datas:\n",
    "    for word in data:\n",
    "        for user in data[word]:\n",
    "            for orientation in data[word][user]:\n",
    "                 for fileName in data[word][user][orientation]:\n",
    "                    \n",
    "                    frameRate = data[word][user][orientation][fileName]['FrameRate']\n",
    "                    no_trials = len(data[word][user][orientation][fileName]['trials'])\n",
    "                    \n",
    "                    #override the trial count as sometime that is missing in annotation\n",
    "                    data[word][user][orientation][fileName]['no_of_trials']= no_trials\n",
    "\n",
    "                    if user+word+'F' in fileName:\n",
    "                        pass \n",
    "                    else:\n",
    "                        print(fileName,user+word+'F',' file annotation err')\n",
    "                    if orientation == 'RightHand' or orientation == 'LeftHand':\n",
    "                        pass\n",
    "                    else:\n",
    "                        print(fileName,user+word+'F',' orientation annotation err')\n",
    "                    \n",
    "                    if frameRate == '30' or frameRate == '24' or frameRate == '15':\n",
    "                        pass\n",
    "                    else:\n",
    "                        print (fileName,' annotation frame rate error')\n",
    "\n",
    "                    data_path = f'{numerical_data_path}/'\n",
    "                    if user in testUser:\n",
    "                        data_path = data_path+'Test/'\n",
    "                    else:\n",
    "                        data_path = data_path+'Training/'\n",
    "            \n",
    "                    data_path = data_path + orientation\n",
    "                    #if orientation == 'RightHand' or orientation == 'LeftHand':\n",
    "                        # Orientation Folder Creation\n",
    "                        #if os.path.exists(data_path):\n",
    "                        #    pass\n",
    "                        #else:\n",
    "                        #    os.makedirs(data_path)\n",
    "                            \n",
    "                    # Word Folder Creation\n",
    "                    word_path = data_path+'/'+word\n",
    "                    \n",
    "                    #if os.path.exists(word_path):\n",
    "                    #    pass\n",
    "                    #else:\n",
    "                    #    os.makedirs(word_path)\n",
    "                        \n",
    "                    # User Folder Creation\n",
    "                    user_path = word_path+'/'+user\n",
    "                \n",
    "                    #if os.path.exists(user_path):\n",
    "                    #    pass\n",
    "                    #else:\n",
    "                    #    os.makedirs(user_path)\n",
    "                     \n",
    "                    fileName_path = user_path+'/'+fileName\n",
    "                    #if os.path.exists(fileName_path):\n",
    "                    #    pass\n",
    "                    #else:\n",
    "                    #    os.makedirs(fileName_path)\n",
    "                        \n",
    "                \n",
    "                    all_npy_path = fileName_path+'/'+'all_npy'\n",
    "                \n",
    "                    source_path = f'{video_data_folder}/{word}/'\n",
    "                    #print(\"Extracting npy \",source_path,fileName_path)\n",
    "                    exception_flag = False\n",
    "                    already_npy = False\n",
    "                    try:\n",
    "                        if os.path.exists(all_npy_path):\n",
    "                            pass\n",
    "                            already_npy = True\n",
    "                            #print('already npy')\n",
    "                        else: \n",
    "                            os.makedirs(all_npy_path)\n",
    "                            # print(\"all npy created\")\n",
    "                            extractNpy(source_path,all_npy_path,fileName)\n",
    "                            already_npy = False\n",
    "                    except:\n",
    "                        exception_flag = True\n",
    "                        print('Something Wrong in the file : ',all_npy_path)\n",
    "                    #Trial Folders Creation\n",
    "                    trial_path = fileName_path+'/'\n",
    "                \n",
    "                \n",
    "                    i=0\n",
    "                    for i in range(0,no_trials):\n",
    "                        trial_folder = trial_path+f't{str(i)}'\n",
    "                        \n",
    "                        if os.path.exists(trial_folder):\n",
    "                            pass\n",
    "                            \n",
    "                        else:\n",
    "                            os.makedirs(trial_folder)\n",
    "                            \n",
    "                            \n",
    "                            #print(f'{trial_folder} folder created.')\n",
    "                        starting = data[word][user][orientation][fileName]['trials'][str(i)]['starting']\n",
    "                        ending = data[word][user][orientation][fileName]['trials'][str(i)]['ending']\n",
    "                        diff = ending - starting\n",
    "                        if frameRate == '15':\n",
    "                            diff = diff * 2\n",
    "                        elif frameRate == '24':\n",
    "                            diff = math.ceil(diff * (5/4))\n",
    "                        #elif frameRate == '30':\n",
    "                        #    diff = diff\n",
    "                        # else:\n",
    "                        #       print(\"Error in Frame Rate in Annotation :\",frameRate)\n",
    "                        \n",
    "                        if exception_flag==False and already_npy ==False:\n",
    "                            frame=0\n",
    "                            for frame in range(starting,ending+1):\n",
    "                                #print(word,user,i,frame)\n",
    "                                shutil.copy(all_npy_path+'/'+str(frame)+'.npy', trial_folder+'/'+str(frame)+'.npy')\n",
    "                        #else:\n",
    "                        #    print(f'Orientation Error for file {word} {user}')\n",
    "                        \n",
    "                        # do some statistics-----------------------------\n",
    "                        total_trails +=1\n",
    "\n",
    "                        if user in testUser:\n",
    "                            if orientation == 'RightHand':\n",
    "                                test_right_trials+=1\n",
    "                            elif orientation == 'LeftHand':\n",
    "                                test_left_trials+=1\n",
    "                        else:\n",
    "                            if orientation == 'RightHand':\n",
    "                                training_right_trials+=1\n",
    "                            elif orientation == 'LeftHand':\n",
    "                                training_left_trials+=1\n",
    "\n",
    "                        total_frameCount+=diff\n",
    "                        \n",
    "\n",
    "                        if diff > max_frame: \n",
    "                            max_frame = diff\n",
    "                            max_start = starting\n",
    "                            max_end = ending   \n",
    "                            max_filename = fileName\n",
    "                            max_ind = i \n",
    "                        if diff < min_frame: \n",
    "                            min_frame = diff\n",
    "                            min_start = starting\n",
    "                            min_end = ending    \n",
    "                            min_filename = fileName\n",
    "                            min_ind = i \n",
    "                        # statistics end ----------------------------------\n",
    "\n",
    "                    # end of trial loop\n",
    "                    \n",
    "MAX_FRAME =max_frame+1\n",
    "min_frame=min_frame+1\n",
    "# total_frameCount +=total_trails\n",
    "avegra_no_frames= 1+total_frameCount/total_trails\n",
    "print(\"Max frame is\",MAX_FRAME,max_filename,max_ind,max_start, max_end)\n",
    "print(\"Min frame is\",min_frame,min_filename,min_ind,min_start, min_end)\n",
    "print(\"No of trials: \",total_trails)\n",
    "print(\"Avg frames per trial: \",avegra_no_frames)\n",
    "print('Total Training instances: ',training_right_trials+training_left_trials,' Right Hand: ',training_right_trials,' Left Hand: ',training_left_trials)\n",
    "print('Total Test instances: ',test_right_trials+test_left_trials,' Right Hand: ',test_right_trials,' Left Hand: ',test_left_trials)\n",
    "# print('TOTAL INSTANCES: ',training_right_trials+training_left_trials+test_right_trials+test_left_trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for data in datas:\n",
    "    for word in data:\n",
    "        for user in data[word]:\n",
    "            for orientation in data[word][user]:\n",
    "                 for fileName in data[word][user][orientation]:\n",
    "                    \n",
    "                    frameRate = data[word][user][orientation][fileName]['FrameRate']\n",
    "                    no_trials = len(data[word][user][orientation][fileName]['trials'])\n",
    "                    \n",
    "                    #override the trial count as sometime that is missing in annotation\n",
    "                    data[word][user][orientation][fileName]['no_of_trials']= no_trials\n",
    "\n",
    "                    #fileName_text = data[word][user][orientation][fileName]['FileName']\n",
    "                    #orientation_text = data[word][user][orientation][fileName]['Orientation']\n",
    "                    \n",
    "                    data_path = f'{numerical_data_path}/'\n",
    "                    destination_path = data_path+'/Calibrated'\n",
    "                    if user in  testUser:\n",
    "                        data_path = data_path+'/Test'\n",
    "                        destination_path = destination_path+'/Test'\n",
    "                    else:\n",
    "                        data_path = data_path+'/Training'\n",
    "                        destination_path = destination_path+'/Training'\n",
    "\n",
    "                    lhFlag = False\n",
    "                    if(orientation == 'LeftHand'):\n",
    "                        lhFlag = True\n",
    "                        # flip_destination_path = f'{destination_path}/{orientation}_FLIPPED/{word}/{user}/{fileName}' \n",
    "                        flip_cal_destination_path = f'{destination_path}/{orientation}_FLIPPED_CALIB/{word}/{user}/{fileName}' \n",
    "                        #print(flip_destination_path)\n",
    "                    #print(flip_destination_path)\n",
    "                    #print(lhFlag)\n",
    "                    data_path = f'{data_path}/{orientation}/{word}/{user}/{fileName}'\n",
    "                    destination_path = f'{destination_path}/{orientation}/{word}/{user}/{fileName}'                          \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    ref_x=0\n",
    "                    ref_y=0\n",
    "                    ref_d=0\n",
    "                    i=0\n",
    "                    for i in range(0,no_trials):\n",
    "                        src_trial_folder = f'{data_path}/t{i}'\n",
    "                        dest_trial_folder = f'{destination_path}/t{i}'\n",
    "                        if os.path.exists(dest_trial_folder):\n",
    "                            pass\n",
    "                        else:\n",
    "                            os.makedirs(dest_trial_folder)\n",
    "                        #print(lhFlag)\n",
    "                        if(lhFlag == True):\n",
    "                            #print('left hand trial folder creation if')\n",
    "                            # flip_dest_trial_folder = f'{flip_destination_path}/t{i}'\n",
    "                            flip_cal_dest_trial_folder = f'{flip_cal_destination_path}/t{i}'\n",
    "                            # if os.path.exists(flip_dest_trial_folder):\n",
    "                                \n",
    "                            #     pass\n",
    "                            # else:\n",
    "                            #     os.makedirs(flip_dest_trial_folder)\n",
    "                                \n",
    "\n",
    "                            if os.path.exists(flip_cal_dest_trial_folder):\n",
    "                                #print(flip_dest_trial_folder,' exists')\n",
    "                                pass\n",
    "                            else:\n",
    "                                os.makedirs(flip_cal_dest_trial_folder)    \n",
    "                            \n",
    "                        starting = data[word][user][orientation][fileName]['trials'][str(i)]['starting']\n",
    "                        ending = data[word][user][orientation][fileName]['trials'][str(i)]['ending']\n",
    "                        # if first trial, starting frame will be calibration frame\n",
    "                        \n",
    "                        if i == 0:\n",
    "                            #load the starting npy\n",
    "                            starting_npy=f'{src_trial_folder}/{starting}.npy'\n",
    "                            #print(starting_npy)\n",
    "                            calib_npy=np.load(starting_npy);\n",
    "                            #print(calib_npy)\n",
    "                            #pose \n",
    "                            #face \n",
    "                            #lh \n",
    "                            #rh \n",
    "                            keypoints3D=calib_npy.reshape(-1,3)\n",
    "                            left_shoulder = keypoints3D[11]\n",
    "                            right_shoulder = keypoints3D[12]\n",
    "                            ref_x=(left_shoulder[0]+right_shoulder[0])/2\n",
    "                            ref_y=(left_shoulder[1]+right_shoulder[1])/2\n",
    "                            ref_d=(left_shoulder[2]+right_shoulder[2])/2\n",
    "                            #print('start: ')\n",
    "                            #print(ref_x,left_shoulder[0],right_shoulder[0],ref_y,left_shoulder[1],right_shoulder[1],ref_d,left_shoulder[2],right_shoulder[2] )\n",
    "                            #print(ref_x,left_shoulder[0]] )\n",
    "                        \n",
    "                        #calibrate all frames, FLIP left hand with right hand, calibrate flipped\n",
    "                        frame=0\n",
    "                        for frame in range(starting,ending+1):\n",
    "                            src_npy_path=f'{src_trial_folder}/{frame}.npy'\n",
    "                            src_npy=np.load(src_npy_path);\n",
    "                            srcKeypoints3D=src_npy.reshape(-1,3)\n",
    "\n",
    "                            if(len(srcKeypoints3D) ==543 ):\n",
    "                                pass\n",
    "                            else:\n",
    "                                print('LandMark error during npy')\n",
    "                            \n",
    "                            if (lhFlag == True):\n",
    "                                flip_src_npy=np.load(src_npy_path);\n",
    "                                flip_srcKeypoints3D=flip_src_npy.reshape(-1,3)\n",
    "                                flip_ref_x = (flip_srcKeypoints3D[11][0]+flip_srcKeypoints3D[12][0])/2\n",
    "                            #print(srcKeypoints3D)\n",
    "                            #normalize the keypoints\n",
    "                            #print(srcKeypoints3D[1628])\n",
    "                            \n",
    "                            #print(ref_x)\n",
    "                            \n",
    "                            \n",
    "                            #print(ref_y)\n",
    "                            #calibratedNp=np.array={}\n",
    "                            #deal with missing values also........\n",
    "                            keypoint_i=0\n",
    "                            for keypoint_i in range(0,543):\n",
    "\n",
    "                                src3d=srcKeypoints3D[keypoint_i]\n",
    "                                x=src3d[0]\n",
    "                                y=src3d[1]\n",
    "                                d=src3d[2]\n",
    "                                if(x<=0.0 and y <=0.0 and d<=0.0) :\n",
    "                                   #missing poing\n",
    "                                   continue\n",
    "\n",
    "                                src3d[0]=x-ref_x\n",
    "                                src3d[1]=y-ref_y\n",
    "                                src3d[2]=d-ref_d\n",
    "\n",
    "                                if(lhFlag == True):\n",
    "                                    #flip on original data only hand points last 21 and then 21 points\n",
    "                                    # swapping not done yet\n",
    "                                    mirror_points={13,14,15,16,17,18,19.20,21,22} \n",
    "                                    if(keypoint_i in mirror_points or keypoint_i >=501):\n",
    "                                        flip_src3d=flip_srcKeypoints3D[keypoint_i]\n",
    "                                        flip_src3d[0]=flip_src3d[0]-flip_ref_x\n",
    "                                        flip_src3d[0]=-flip_src3d[0]\n",
    "                                        flip_src3d[0]=flip_ref_x+flip_src3d[0] \n",
    "                                                               \n",
    "                            #for finished        \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "\n",
    "                            dest_trial_npy_path = dest_trial_folder+'/'+str(frame)+'.npy'\n",
    "                            np.save(dest_trial_npy_path,srcKeypoints3D.flatten())\n",
    "                            # exchange hands and shoulder point for LeftHand Orientation\n",
    "                            if (lhFlag == True):\n",
    "                                #swap hands and related pose points\n",
    "\n",
    "                                swap_points={11,13,15,17,19,21} \n",
    "                                sp=0\n",
    "                                for sp in swap_points:\n",
    "                                    left_x= flip_srcKeypoints3D[sp][0]\n",
    "                                    left_y= flip_srcKeypoints3D[sp][1]\n",
    "                                    left_d= flip_srcKeypoints3D[sp][2]\n",
    "                                \n",
    "                                    right_x= flip_srcKeypoints3D[sp+1][0]\n",
    "                                    right_y= flip_srcKeypoints3D[sp+1][1]\n",
    "                                    right_d= flip_srcKeypoints3D[sp+1][2]\n",
    "\n",
    "                                                               \n",
    "                                    flip_srcKeypoints3D[sp][0] =right_x\n",
    "                                    flip_srcKeypoints3D[sp][1] =right_y\n",
    "                                    flip_srcKeypoints3D[sp][2] =right_d\n",
    "                                \n",
    "                                    flip_srcKeypoints3D[sp+1][0]= left_x\n",
    "                                    flip_srcKeypoints3D[sp+1][1]= left_y\n",
    "                                    flip_srcKeypoints3D[sp+1][2]= left_d\n",
    "\n",
    "                                #left right hand swap\n",
    "                                hpoint_i=0\n",
    "                                for hpoint_i in range(0,21):\n",
    "                                    left_x=flip_srcKeypoints3D[501+hpoint_i][0]\n",
    "                                    left_y=flip_srcKeypoints3D[501+hpoint_i][1]\n",
    "                                    left_d=flip_srcKeypoints3D[501+hpoint_i][2]\n",
    "                                    \n",
    "                                    right_x=flip_srcKeypoints3D[522+hpoint_i][0]\n",
    "                                    right_y=flip_srcKeypoints3D[522+hpoint_i][1]\n",
    "                                    right_d=flip_srcKeypoints3D[522+hpoint_i][2]\n",
    "\n",
    "                                    flip_srcKeypoints3D[501+hpoint_i][0] =right_x\n",
    "                                    flip_srcKeypoints3D[501+hpoint_i][1] =right_y\n",
    "                                    flip_srcKeypoints3D[501+hpoint_i][2] =right_d\n",
    "\n",
    "                                    flip_srcKeypoints3D[522+hpoint_i][0] =left_x\n",
    "                                    flip_srcKeypoints3D[522+hpoint_i][1] =left_y\n",
    "                                    flip_srcKeypoints3D[522+hpoint_i][2] =left_d\n",
    "                                                                        \n",
    "                                    \n",
    "                                    \n",
    "\n",
    "                                #flip_dest_trial_npy_path = flip_dest_trial_folder+'/'+str(frame)+'.npy'\n",
    "                                \n",
    "\n",
    "                                # np.save(flip_dest_trial_npy_path,flip_srcKeypoints3D.flatten())\n",
    "                                \n",
    "                                \n",
    "                                #lefthand flip without calibration finished\n",
    "\n",
    "                                # do calibration for this frame\n",
    "                                handkey_i=0\n",
    "                                for handkey_i in range(0,543):\n",
    "                                    flip_src3d=flip_srcKeypoints3D[handkey_i]\n",
    "                                    flip_x=flip_src3d[0]\n",
    "                                    flip_y=flip_src3d[1]\n",
    "                                    flip_d=flip_src3d[2]\n",
    "                                    #missing value\n",
    "                                    if(flip_x<=0.0 and flip_y <=0.0 and flip_d <=0.0):\n",
    "                                        continue\n",
    "                                    flip_src3d[0]=flip_x-ref_x\n",
    "                                    flip_src3d[1]=flip_y-ref_y\n",
    "                                    flip_src3d[2]=flip_d-ref_d\n",
    "                                flip_cal_dest_trial_npy_path = flip_cal_dest_trial_folder+'/'+str(frame)+'.npy'\n",
    "                                #print(flip_dest_trial_npy_path)\n",
    "                                np.save(flip_cal_dest_trial_npy_path,flip_srcKeypoints3D.flatten())\n",
    "                            #if lhFlag True did flip and calibrations\n",
    "                            #shutil.copy(src_trial_folder+'/'+str(frame)+'.npy', dest_trial_folder+'/'+str(frame)+'.npy')\n",
    "                        # loop for frames of a trial\n",
    "                    #loop for trials\n",
    "                    \n",
    "                        \n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertionSort(array):\n",
    "\n",
    "    for step in range(1, len(array)):\n",
    "        key = array[step]\n",
    "        j = step - 1\n",
    "        \n",
    "        # Compare key with each element on the left of it until an element smaller than it is found\n",
    "        # For descending order, change key<array[j] to key>array[j].        \n",
    "        while j >= 0 and key < array[j]:\n",
    "            array[j + 1] = array[j]\n",
    "            j = j - 1\n",
    "        \n",
    "        # Place key at after the element just smaller than it.\n",
    "        array[j + 1] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_flatten(xss):\n",
    "    return[x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "{'W355': {'ClassLabel': 'W355'}, 'W356': {'ClassLabel': 'W356'}, 'W215': {'ClassLabel': 'W215'}, 'W216': {'ClassLabel': 'W216'}, 'W19': {'ClassLabel': 'W19'}, 'W20': {'ClassLabel': 'W20'}, 'W213': {'ClassLabel': 'W213'}, 'W214': {'ClassLabel': 'W214'}, 'W91': {'ClassLabel': 'W91'}, 'W92': {'ClassLabel': 'W92'}, 'W357': {'ClassLabel': 'W357'}, 'W358': {'ClassLabel': 'W358'}, 'W3': {'ClassLabel': 'W3'}, 'W4': {'ClassLabel': 'W4'}, 'W351': {'ClassLabel': 'W351'}, 'W352': {'ClassLabel': 'W352'}, 'W11': {'ClassLabel': 'W11'}, 'W12': {'ClassLabel': 'W12'}, 'W359': {'ClassLabel': 'W359'}, 'W360': {'ClassLabel': 'W360'}, 'W37': {'ClassLabel': 'W37'}, 'W38': {'ClassLabel': 'W38'}, 'W99': {'ClassLabel': 'W99'}, 'W100': {'ClassLabel': 'W100'}, 'W49': {'ClassLabel': 'W49'}, 'W50': {'ClassLabel': 'W50'}, 'W43': {'ClassLabel': 'W43'}, 'W44': {'ClassLabel': 'W44'}, 'W47': {'ClassLabel': 'W47'}, 'W48': {'ClassLabel': 'W48'}, 'W1': {'ClassLabel': 'W1'}, 'W2': {'ClassLabel': 'W2'}, 'W93': {'ClassLabel': 'W93'}, 'W94': {'ClassLabel': 'W94'}, 'W9': {'ClassLabel': 'W9'}, 'W10': {'ClassLabel': 'W10'}, 'W211': {'ClassLabel': 'W211'}, 'W212': {'ClassLabel': 'W212'}, 'W41': {'ClassLabel': 'W41'}, 'W42': {'ClassLabel': 'W42'}, 'W39': {'ClassLabel': 'W39'}, 'W40': {'ClassLabel': 'W40'}, 'W353': {'ClassLabel': 'W353'}, 'W354': {'ClassLabel': 'W354'}, 'W45': {'ClassLabel': 'W45'}, 'W46': {'ClassLabel': 'W46'}, 'W95': {'ClassLabel': 'W95'}, 'W96': {'ClassLabel': 'W96'}, 'W5': {'ClassLabel': 'W5'}, 'W6': {'ClassLabel': 'W6'}, 'W97': {'ClassLabel': 'W97'}, 'W98': {'ClassLabel': 'W98'}, 'W111': {'ClassLabel': 'W111'}, 'W112': {'ClassLabel': 'W112'}, 'W217': {'ClassLabel': 'W217'}, 'W218': {'ClassLabel': 'W218'}, 'W219': {'ClassLabel': 'W219'}, 'W220': {'ClassLabel': 'W220'}, 'W7': {'ClassLabel': 'W7'}, 'W8': {'ClassLabel': 'W8'}}\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19, 20, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 111, 112, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360]\n",
      "60\n",
      "{'W355': {'ClassLabel': 'W355', 'ClassNumer': 54}, 'W356': {'ClassLabel': 'W356', 'ClassNumer': 55}, 'W215': {'ClassLabel': 'W215', 'ClassNumer': 44}, 'W216': {'ClassLabel': 'W216', 'ClassNumer': 45}, 'W19': {'ClassLabel': 'W19', 'ClassNumer': 12}, 'W20': {'ClassLabel': 'W20', 'ClassNumer': 13}, 'W213': {'ClassLabel': 'W213', 'ClassNumer': 42}, 'W214': {'ClassLabel': 'W214', 'ClassNumer': 43}, 'W91': {'ClassLabel': 'W91', 'ClassNumer': 28}, 'W92': {'ClassLabel': 'W92', 'ClassNumer': 29}, 'W357': {'ClassLabel': 'W357', 'ClassNumer': 56}, 'W358': {'ClassLabel': 'W358', 'ClassNumer': 57}, 'W3': {'ClassLabel': 'W3', 'ClassNumer': 2}, 'W4': {'ClassLabel': 'W4', 'ClassNumer': 3}, 'W351': {'ClassLabel': 'W351', 'ClassNumer': 50}, 'W352': {'ClassLabel': 'W352', 'ClassNumer': 51}, 'W11': {'ClassLabel': 'W11', 'ClassNumer': 10}, 'W12': {'ClassLabel': 'W12', 'ClassNumer': 11}, 'W359': {'ClassLabel': 'W359', 'ClassNumer': 58}, 'W360': {'ClassLabel': 'W360', 'ClassNumer': 59}, 'W37': {'ClassLabel': 'W37', 'ClassNumer': 14}, 'W38': {'ClassLabel': 'W38', 'ClassNumer': 15}, 'W99': {'ClassLabel': 'W99', 'ClassNumer': 36}, 'W100': {'ClassLabel': 'W100', 'ClassNumer': 37}, 'W49': {'ClassLabel': 'W49', 'ClassNumer': 26}, 'W50': {'ClassLabel': 'W50', 'ClassNumer': 27}, 'W43': {'ClassLabel': 'W43', 'ClassNumer': 20}, 'W44': {'ClassLabel': 'W44', 'ClassNumer': 21}, 'W47': {'ClassLabel': 'W47', 'ClassNumer': 24}, 'W48': {'ClassLabel': 'W48', 'ClassNumer': 25}, 'W1': {'ClassLabel': 'W1', 'ClassNumer': 0}, 'W2': {'ClassLabel': 'W2', 'ClassNumer': 1}, 'W93': {'ClassLabel': 'W93', 'ClassNumer': 30}, 'W94': {'ClassLabel': 'W94', 'ClassNumer': 31}, 'W9': {'ClassLabel': 'W9', 'ClassNumer': 8}, 'W10': {'ClassLabel': 'W10', 'ClassNumer': 9}, 'W211': {'ClassLabel': 'W211', 'ClassNumer': 40}, 'W212': {'ClassLabel': 'W212', 'ClassNumer': 41}, 'W41': {'ClassLabel': 'W41', 'ClassNumer': 18}, 'W42': {'ClassLabel': 'W42', 'ClassNumer': 19}, 'W39': {'ClassLabel': 'W39', 'ClassNumer': 16}, 'W40': {'ClassLabel': 'W40', 'ClassNumer': 17}, 'W353': {'ClassLabel': 'W353', 'ClassNumer': 52}, 'W354': {'ClassLabel': 'W354', 'ClassNumer': 53}, 'W45': {'ClassLabel': 'W45', 'ClassNumer': 22}, 'W46': {'ClassLabel': 'W46', 'ClassNumer': 23}, 'W95': {'ClassLabel': 'W95', 'ClassNumer': 32}, 'W96': {'ClassLabel': 'W96', 'ClassNumer': 33}, 'W5': {'ClassLabel': 'W5', 'ClassNumer': 4}, 'W6': {'ClassLabel': 'W6', 'ClassNumer': 5}, 'W97': {'ClassLabel': 'W97', 'ClassNumer': 34}, 'W98': {'ClassLabel': 'W98', 'ClassNumer': 35}, 'W111': {'ClassLabel': 'W111', 'ClassNumer': 38}, 'W112': {'ClassLabel': 'W112', 'ClassNumer': 39}, 'W217': {'ClassLabel': 'W217', 'ClassNumer': 46}, 'W218': {'ClassLabel': 'W218', 'ClassNumer': 47}, 'W219': {'ClassLabel': 'W219', 'ClassNumer': 48}, 'W220': {'ClassLabel': 'W220', 'ClassNumer': 49}, 'W7': {'ClassLabel': 'W7', 'ClassNumer': 6}, 'W8': {'ClassLabel': 'W8', 'ClassNumer': 7}}\n"
     ]
    }
   ],
   "source": [
    "# generating index for class labels\n",
    "# the index will be used as label in ML\n",
    "\n",
    "# class one hot encoding\n",
    "classAnnotation={}\n",
    "for data in datas:\n",
    "    for word in data:\n",
    "        try:\n",
    "            classAnnotation[word]        \n",
    "        except:\n",
    "            classAnnotation[word]={}\n",
    "        try:\n",
    "            classAnnotation[word]['ClassLabel']        \n",
    "        except:\n",
    "            classAnnotation[word]['ClassLabel'] ={}\n",
    "        classAnnotation[word]['ClassLabel'] =word\n",
    "\n",
    "print(len(classAnnotation))\n",
    "print(classAnnotation)\n",
    "\n",
    "numbers = []\n",
    "for cl in classAnnotation:\n",
    "    classLabel=classAnnotation[cl]['ClassLabel']\n",
    "    temp = int(classLabel[1:])\n",
    "    numbers.append(temp)\n",
    "insertionSort(numbers)\n",
    "print(numbers)\n",
    "\n",
    "classIndex=0\n",
    "for num in numbers:\n",
    "    classLabel='W'+str(num)\n",
    "    try:\n",
    "        classAnnotation[classLabel]['ClassNumer']\n",
    "    except:\n",
    "        classAnnotation[classLabel]['ClassNumer']={}\n",
    "    classAnnotation[classLabel]['ClassNumer'] =classIndex\n",
    "    classIndex =classIndex+1\n",
    "\n",
    "NO_CLASSES =len(classAnnotation)\n",
    "print(classIndex)\n",
    "print(classAnnotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_HAND_ORIENTATION ='LeftHand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating npy array for ML\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data in datas:\n",
    "    for word in data:\n",
    "        for user in data[word]:\n",
    "            for orientation in data[word][user]:\n",
    "                 \n",
    "                 \n",
    "                 for fileName in data[word][user][orientation]:\n",
    "                    \n",
    "                    frameRate = data[word][user][orientation][fileName]['FrameRate']\n",
    "                    no_trials = len(data[word][user][orientation][fileName]['trials'])\n",
    "                    \n",
    "                    #override the trial count as sometime that is missing in annotation\n",
    "                    data[word][user][orientation][fileName]['no_of_trials']= no_trials\n",
    "\n",
    "                    if frameRate == '30' or frameRate == '24' or frameRate == '15':\n",
    "                        pass\n",
    "                    else:\n",
    "                        print (fileName,' frame rate error in NPY FRAME CONVERSION')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    #data_path = 'NumericalData'\n",
    "                    #data_path = data_path+'/Calibrated'\n",
    "\n",
    "                    trainorTest = 'Training'\n",
    "                    if user in testUser:\n",
    "                        trainorTest='Test'\n",
    "                    \n",
    "                    \n",
    "                    ori_folder = orientation\n",
    "                    if orientation == LEFT_HAND_ORIENTATION:\n",
    "                        data_path_org_left = f'{numerical_data_path}/Calibrated/{trainorTest}/{ori_folder}/{word}/{user}/{fileName}'\n",
    "                        dest_path_org_left = f'{numerical_data_path}/ML/{trainorTest}/{orientation}_NO_FLIP'\n",
    "                        ori_folder ='LeftHand_FLIPPED_CALIB'\n",
    "                    \n",
    "                    data_path = f'{numerical_data_path}/Calibrated/{trainorTest}/{ori_folder}/{word}/{user}/{fileName}'\n",
    "\n",
    "                    dest_path = f'{numerical_data_path}/ML/{trainorTest}/{orientation}'\n",
    "                    #classLabel = word\n",
    "                    classIndex =classAnnotation[word]['ClassNumer']\n",
    "                    #print(classLabel,' ',classIndex)\n",
    "\n",
    "                   \n",
    "                    \n",
    "                    #frame_dup_counter= frameDupRate\n",
    "                    trial=0\n",
    "                    for trial in range(0,no_trials):\n",
    "                   \n",
    "                        trial_path=f'{data_path}/t{trial}'\n",
    "                        if orientation == 'LeftHand':\n",
    "                            trial_path_org_left=f'{data_path_org_left}/t{trial}'\n",
    "\n",
    "                        #print(trial_path,' ',classIndex)\n",
    "                        starting = data[word][user][orientation][fileName]['trials'][str(trial)]['starting']\n",
    "                        ending = data[word][user][orientation][fileName]['trials'][str(trial)]['ending']\n",
    "                        npy_array=[]\n",
    "                        if orientation == LEFT_HAND_ORIENTATION:\n",
    "                            npy_array_org_left=[]\n",
    "                        \n",
    "                        fcount=0\n",
    "                        dupcount=0\n",
    "                        npy_frame=0\n",
    "                        for npy_frame in range(starting,ending+1):\n",
    "                            fcount=fcount+1;\n",
    "                            if (fcount+dupcount) > MAX_FRAME:\n",
    "                                print('Frame Excceded')\n",
    "                                continue\n",
    "\n",
    "                            npy_frame_path =f'{trial_path}/{npy_frame}.npy'\n",
    "                                                           \n",
    "                            npy=np.load(npy_frame_path)\n",
    "                            #print(len(npy))\n",
    "                            if (len(npy) >1629):\n",
    "                                print('NPY WRONG POSE/VISIBILITY DATA INCLUDED FOR ZERO POSE LANDMARK')\n",
    "                            npy_array.append(npy)\n",
    "                            \n",
    "\n",
    "                            if orientation == LEFT_HAND_ORIENTATION:\n",
    "                                npy_frame_path_org_left =f'{trial_path_org_left}/{npy_frame}.npy'\n",
    "                                npy_org_left=np.load(npy_frame_path_org_left)\n",
    "                                npy_array_org_left.append(npy_org_left)\n",
    "                                \n",
    "\n",
    "                            #npy_array_oneIns[fcount]=npy\n",
    "                            #npy.reshape(-1,3)\n",
    "                            \n",
    "                            \n",
    "\n",
    "                            \n",
    "                            \n",
    "                            if frameRate =='15':\n",
    "                                #npy dup\n",
    "                                npy_array.append(npy)\n",
    "                                \n",
    "                                if orientation == LEFT_HAND_ORIENTATION:\n",
    "                                    npy_array_org_left.append(npy_org_left)\n",
    "                                    \n",
    "                                dupcount =dupcount+1\n",
    "                                \n",
    "                            elif frameRate == '24' and fcount % 4 == 0:\n",
    "                                #npy dup\n",
    "                                npy_array.append(npy)\n",
    "                                \n",
    "                                if orientation == LEFT_HAND_ORIENTATION:\n",
    "                                    npy_array_org_left.append(npy_org_left)\n",
    "                                    \n",
    "                                dupcount =dupcount+1\n",
    "                        #for srtaring ending frame of a trial\n",
    "                       \n",
    "                        \n",
    "                        fcount =fcount+dupcount\n",
    "                        #print('count: ',count)\n",
    "                        count=0\n",
    "                        for count in range(fcount,MAX_FRAME):\n",
    "                            npy =np.zeros(543*3)\n",
    "                            npy_array.append(npy)\n",
    "                            \n",
    "                            if orientation == LEFT_HAND_ORIENTATION:\n",
    "                                npy =np.zeros(543*3)\n",
    "                                npy_array_org_left.append(npy)\n",
    "                        #print('end count: ',count)    \n",
    "                        #now class index\n",
    "                        #class_array.append(classIndex);\n",
    "                        #print(len(npy_array))\n",
    "                        dest_class_path=f'{dest_path}/{str(classIndex)}'\n",
    "                        if os.path.exists(dest_class_path):\n",
    "                            pass\n",
    "                        else:\n",
    "                            os.makedirs(dest_class_path)\n",
    "                        \n",
    "                        dest_file_path =f'{dest_class_path}/{classIndex}_{user}_{trial}_{fileName}.npy'                                            \n",
    "                        np.save(dest_file_path,my_flatten(npy_array))\n",
    "\n",
    "                        if orientation == LEFT_HAND_ORIENTATION: \n",
    "                            dest_class_path_org_left=f'{dest_path_org_left}/{str(classIndex)}'\n",
    "                            if os.path.exists(dest_class_path_org_left):\n",
    "                                pass\n",
    "                            else:\n",
    "                                os.makedirs(dest_class_path_org_left)\n",
    "                            \n",
    "                            dest_file_path_org_left =f'{dest_class_path_org_left}/{classIndex}_{user}_{trial}_{fileName}.npy'                        \n",
    "                            np.save(dest_file_path_org_left,my_flatten(npy_array_org_left))\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "                        \n",
    "                            \n",
    "\n",
    "\n",
    "                            \n",
    "\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating npy array for ML \n",
    "#PROLONG THE SHORT GESTURE BY DUPLICATING\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data in datas:\n",
    "    for word in data:\n",
    "        for user in data[word]:\n",
    "            for orientation in data[word][user]:\n",
    "                 \n",
    "                 \n",
    "                 for fileName in data[word][user][orientation]:\n",
    "                    \n",
    "                    frameRate = data[word][user][orientation][fileName]['FrameRate']\n",
    "                    no_trials = len(data[word][user][orientation][fileName]['trials'])\n",
    "                    \n",
    "                    #override the trial count as sometime that is missing in annotation\n",
    "                    data[word][user][orientation][fileName]['no_of_trials']= no_trials\n",
    "\n",
    "                    if frameRate == '30' or frameRate == '24' or frameRate == '15':\n",
    "                        pass\n",
    "                    else:\n",
    "                        print (fileName,' frame rate error in NPY FRAME CONVERSION')\n",
    "\n",
    "                    if (len(npy) >1629):\n",
    "                                print('NPY WRONG POSE/VISIBILITY DATA INCLUDED FOR ZERO POSE LANDMARK')\n",
    "                    if (len(npy) <1629):\n",
    "                                print('NPY WRONG POSE/VISIBILITY DATA INCLUDED FOR ZERO POSE LANDMARK',fileName)\n",
    "                    #data_path = 'NumericalData'\n",
    "                    #data_path = data_path+'/Calibrated'\n",
    "\n",
    "                    trainorTest = 'Training'\n",
    "                    if user in testUser:\n",
    "                        trainorTest='Test'\n",
    "                    \n",
    "                    \n",
    "                    ori_folder = orientation\n",
    "                    if orientation == LEFT_HAND_ORIENTATION:\n",
    "                        data_path_org_left = f'{numerical_data_path}/Calibrated/{trainorTest}/{ori_folder}/{word}/{user}/{fileName}'\n",
    "                        dest_path_org_left = f'{numerical_data_path}/ML_PROLONG/{trainorTest}/{orientation}_NO_FLIP'\n",
    "                        ori_folder ='LeftHand_FLIPPED_CALIB'\n",
    "                    \n",
    "                    data_path = f'{numerical_data_path}/Calibrated/{trainorTest}/{ori_folder}/{word}/{user}/{fileName}'\n",
    "\n",
    "                    dest_path = f'{numerical_data_path}/ML_PROLONG/{trainorTest}/{orientation}'\n",
    "                    #classLabel = word\n",
    "                    classIndex =classAnnotation[word]['ClassNumer']\n",
    "                    #print(classLabel,' ',classIndex)\n",
    "\n",
    "                   \n",
    "                    \n",
    "                    #frame_dup_counter= frameDupRate\n",
    "                    trial=0\n",
    "                    for trial in range(0,no_trials):\n",
    "                   \n",
    "                        trial_path=f'{data_path}/t{trial}'\n",
    "                        if orientation == 'LeftHand':\n",
    "                            trial_path_org_left=f'{data_path_org_left}/t{trial}'\n",
    "\n",
    "                        #print(trial_path,' ',classIndex)\n",
    "                        starting = data[word][user][orientation][fileName]['trials'][str(trial)]['starting']\n",
    "                        ending = data[word][user][orientation][fileName]['trials'][str(trial)]['ending']\n",
    "                        npy_array=[]\n",
    "                        if orientation == LEFT_HAND_ORIENTATION:\n",
    "                            npy_array_org_left=[]\n",
    "                        \n",
    "                        \n",
    "                        tf =math.ceil((ending-starting+1)*30/int(frameRate))\n",
    "                        dupRatio =MAX_FRAME//tf\n",
    "                        \n",
    "                        fcount=0\n",
    "                        dupcount=0\n",
    "                        spreadCount=0\n",
    "                        npy_frame=0\n",
    "                        for npy_frame in range(starting,ending+1):\n",
    "                            fcount=fcount+1;\n",
    "                            if (fcount+dupcount) > MAX_FRAME:\n",
    "                                print('Frame Excceded')\n",
    "                                continue\n",
    "\n",
    "                            npy_frame_path =f'{trial_path}/{npy_frame}.npy'\n",
    "                                                           \n",
    "                            npy=np.load(npy_frame_path)\n",
    "                            #print(len(npy))\n",
    "                            if (len(npy) >1629):\n",
    "                                print('NPY WRONG POSE/VISIBILITY DATA INCLUDED FOR ZERO POSE LANDMARK')\n",
    "                            if (len(npy) <1629):\n",
    "                                print('NPY WRONG POSE/VISIBILITY DATA INCLUDED FOR ZERO POSE LANDMARK',fileName)\n",
    "                            \n",
    "                            \n",
    "                            npy_array.append(npy)\n",
    "                            #print('DUP ratio: ',dupRatio)\n",
    "                            dup=1;\n",
    "                            for dup in range(1,dupRatio):\n",
    "                                # print ('duplicate times: ',dup, trial,word,user,dupRatio)\n",
    "                                 npy_array.append(npy)\n",
    "                                 dupcount=dupcount+1\n",
    "                            \n",
    "                            #uniformly spread/duplicate the frames upto max frame\n",
    "                            scFlag=False\n",
    "                            if(spreadCount<(MAX_FRAME -tf*dupRatio)):\n",
    "                                 #print('spread: ',trial,word,user)\n",
    "                                 npy_array.append(npy)\n",
    "                                 spreadCount =spreadCount+1\n",
    "                                 scFlag=True\n",
    "                                 dupcount=dupcount+1\n",
    "                                \n",
    "                            \n",
    "\n",
    "                            if orientation == LEFT_HAND_ORIENTATION:\n",
    "                                npy_frame_path_org_left =f'{trial_path_org_left}/{npy_frame}.npy'\n",
    "                                npy_org_left=np.load(npy_frame_path_org_left)\n",
    "                                npy_array_org_left.append(npy_org_left)\n",
    "                                \n",
    "                                dup=1\n",
    "                                for dup in range(1,dupRatio):\n",
    "                                    npy_array_org_left.append(npy_org_left)\n",
    "                                #uniformly spread/duplicate the frames upto max frame\n",
    "                                \n",
    "                                if scFlag==True:\n",
    "                                    npy_array_org_left.append(npy_org_left)\n",
    "                                 \n",
    "                                \n",
    "\n",
    "                            #npy_array_oneIns[fcount]=npy\n",
    "                            #npy.reshape(-1,3)\n",
    "                            \n",
    "                            \n",
    "\n",
    "                            \n",
    "                            \n",
    "                            if frameRate =='15':\n",
    "                                #npy dup\n",
    "                                npy_array.append(npy)\n",
    "                                dupcount =dupcount+1\n",
    "                                \n",
    "                                dup=1\n",
    "                                for dup in range(1,dupRatio):\n",
    "                                    npy_array.append(npy)\n",
    "                                    dupcount=dupcount+1\n",
    "                                \n",
    "                                if orientation == LEFT_HAND_ORIENTATION:\n",
    "                                    npy_array_org_left.append(npy_org_left)\n",
    "                                    dup =1\n",
    "                                    for dup in range(1,dupRatio):\n",
    "                                        npy_array_org_left.append(npy_org_left)\n",
    "                                \n",
    "                                \n",
    "                            elif frameRate == '24' and fcount % 4 == 0:\n",
    "                                #npy dup\n",
    "                                npy_array.append(npy)\n",
    "                                dupcount =dupcount+1\n",
    "                                dup=1\n",
    "                                for dup in range(1,dupRatio):\n",
    "                                    npy_array.append(npy)\n",
    "                                    dupcount=dupcount+1\n",
    "\n",
    "                                if orientation == LEFT_HAND_ORIENTATION:\n",
    "                                    npy_array_org_left.append(npy_org_left)\n",
    "                                    dup=1\n",
    "                                    for dup in range(1,dupRatio):\n",
    "                                        npy_array_org_left.append(npy_org_left)\n",
    "                                \n",
    "                        #for srtaring ending frame of a trial\n",
    "                       \n",
    "                        #check for zero padding needed\n",
    "                                               \n",
    "                        fcount =fcount+dupcount\n",
    "                        #print('count: ',count)\n",
    "                        count=0\n",
    "                        for count in range(fcount,MAX_FRAME):\n",
    "                            npy =np.zeros(543*3)\n",
    "                            npy_array.append(npy)\n",
    "                            \n",
    "                        \n",
    "                        if orientation == LEFT_HAND_ORIENTATION:\n",
    "                            count=0\n",
    "                            for count in range(fcount,MAX_FRAME):\n",
    "                                npy2 =np.zeros(543*3)\n",
    "                                npy_array_org_left.append(npy2)\n",
    "                        #print('end count: ',count)    \n",
    "                        #now class index\n",
    "                        #class_array.append(classIndex);\n",
    "                        #print(len(npy_array))\n",
    "                        dest_class_path=f'{dest_path}/{str(classIndex)}'\n",
    "                        if os.path.exists(dest_class_path):\n",
    "                            pass\n",
    "                        else:\n",
    "                            os.makedirs(dest_class_path)\n",
    "                        \n",
    "                        dest_file_path =f'{dest_class_path}/{classIndex}_{user}_{trial}_{fileName}.npy'                                            \n",
    "                        np.save(dest_file_path,my_flatten(npy_array))\n",
    "\n",
    "                        if orientation == LEFT_HAND_ORIENTATION: \n",
    "                            #print(len(npy_array_org_left))\n",
    "                            dest_class_path_org_left=f'{dest_path_org_left}/{str(classIndex)}'\n",
    "                            if os.path.exists(dest_class_path_org_left):\n",
    "                                pass\n",
    "                            else:\n",
    "                                os.makedirs(dest_class_path_org_left)\n",
    "                            \n",
    "                            dest_file_path_org_left =f'{dest_class_path_org_left}/{classIndex}_{user}_{trial}_{fileName}.npy'                        \n",
    "                            np.save(dest_file_path_org_left,my_flatten(npy_array_org_left))\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "                        \n",
    "                            \n",
    "\n",
    "\n",
    "                            \n",
    "\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalizeData (norm_path, crossValidationDataPaths,testPaths):\n",
    "    print(\"hello\")\n",
    "    PER_FRAME_FEATURE =1629\n",
    "    min=np.zeros (PER_FRAME_FEATURE)\n",
    "    max=np.zeros (PER_FRAME_FEATURE)\n",
    "    \n",
    "\n",
    "    for i in range (0,PER_FRAME_FEATURE):\n",
    "        min[i]= 9\n",
    "        max[i]= -9\n",
    "\n",
    "    ml_instances_paths=[]\n",
    "    for path in crossValidationDataPaths:   \n",
    "        print('training path: ',path) \n",
    "        classFolders= os.listdir(path)\n",
    "        for classFolder in classFolders:\n",
    "            classFolder_path=f'{path}/{classFolder}'\n",
    "            classTrials =os.listdir(classFolder_path)\n",
    "            for trial in classTrials:\n",
    "                trialPath =f'{classFolder_path}/{trial}'\n",
    "                ml_instances_paths.append(trialPath)           \n",
    "                npy =np.load(trialPath)            \n",
    "                npy_matrix=npy.reshape(-1,PER_FRAME_FEATURE)\n",
    "                feature =0\n",
    "                for feature in range(0,PER_FRAME_FEATURE):\n",
    "                    temp_min = np.min(npy_matrix[:,feature])\n",
    "                    temp_max = np.max(npy_matrix[:,feature])\n",
    "                \n",
    "                    if temp_max>max[feature]:\n",
    "                        max[feature] =temp_max\n",
    "                    if temp_min < min[feature]:\n",
    "                        min[feature] =temp_min\n",
    "    \n",
    "    test_paths=[]\n",
    "    for path in testPaths:    \n",
    "        print('test path: ',path) \n",
    "        classFolders= os.listdir(path)\n",
    "        for classFolder in classFolders:\n",
    "            classFolder_path=f'{path}/{classFolder}'\n",
    "            classTrials =os.listdir(classFolder_path)\n",
    "            for trial in classTrials:\n",
    "                trialPath =f'{classFolder_path}/{trial}'            \n",
    "                test_paths.append(trialPath)\n",
    "                #generate min-max\n",
    "                npy =np.load(trialPath)\n",
    "                npy_matrix=npy.reshape(-1,PER_FRAME_FEATURE)          \n",
    "            \n",
    "                feature=0\n",
    "                for feature in range(0,PER_FRAME_FEATURE):\n",
    "                    temp_min = np.min(npy_matrix[:,feature])\n",
    "                    temp_max = np.max(npy_matrix[:,feature])\n",
    "                \n",
    "                    if temp_max>max[feature]:\n",
    "                        max[feature] =temp_max\n",
    "                    if temp_min < min[feature]:\n",
    "                        min[feature] =temp_min\n",
    "\n",
    "    print('Normalization starting')\n",
    "\n",
    "    for ml_instances_path in ml_instances_paths:         \n",
    "        npy =np.load(ml_instances_path)\n",
    "        npy_matrix=npy.reshape(-1,PER_FRAME_FEATURE)\n",
    "        feature=0\n",
    "        for feature in range(0,PER_FRAME_FEATURE):          \n",
    "            my_range = max[feature]-min[feature]        \n",
    "            npy_matrix[:,feature] = (npy_matrix[:,feature]*100000 -min[feature]*100000)/(my_range*100000+0.00001)     \n",
    "        \n",
    "        #save in file\n",
    "        # toDest_path=f'{norm_path}/{ml_instances_path}'\n",
    "    \n",
    "        #create the target folder\n",
    "        label = ml_instances_path.split('/')\n",
    "        dir_path =''\n",
    "        i=0\n",
    "        for i in range(1,len(label)-1): #omit ../\n",
    "            dir_path=dir_path+label[i]+'/'\n",
    "\n",
    "        dir_path=f'{norm_path}/{dir_path}'\n",
    "        if os.path.exists(dir_path):\n",
    "            pass           \n",
    "                           \n",
    "        else: \n",
    "            os.makedirs(dir_path)    \n",
    "\n",
    "        toDest_path =f'{dir_path}/{label[len(label)-1]}'\n",
    "        np.save(toDest_path,npy_matrix.flatten())\n",
    "\n",
    "    for ml_instances_path in test_paths:  \n",
    "        npy =np.load(ml_instances_path)\n",
    "        npy_matrix=npy.reshape(-1,PER_FRAME_FEATURE)\n",
    "        feature =0\n",
    "        for feature in range(0,PER_FRAME_FEATURE):\n",
    "            my_range =max[feature]-min[feature]\n",
    "            npy_matrix[:,feature] = (npy_matrix[:,feature]*100000 -min[feature]*100000)/(my_range*100000+0.00001)  \n",
    "\n",
    "        #save in file\n",
    "        # toDest_path=f'{norm_path}/{ml_instances_path}'\n",
    "\n",
    "        label = ml_instances_path.split('/')\n",
    "        dir_path =''\n",
    "        i=0\n",
    "        for i in range(1,len(label)-1):  #omit ../\n",
    "            dir_path=dir_path+label[i]+'/'\n",
    "\n",
    "        dir_path=f'{norm_path}/{dir_path}'\n",
    "        if os.path.exists(dir_path):\n",
    "            pass                                                   \n",
    "        else: \n",
    "            os.makedirs(dir_path)\n",
    "        \n",
    "        toDest_path =f'{dir_path}/{label[len(label)-1]}'\n",
    "        np.save(toDest_path,npy_matrix.flatten())\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize\n",
      "hello\n",
      "training path:  ../NumericalData/ML_PROLONG/Training/RightHand\n",
      "training path:  ../NumericalData/ML_PROLONG/Training/LeftHand_NO_FLIP\n",
      "test path:  ../NumericalData/ML_PROLONG/Test/RightHand\n",
      "test path:  ../NumericalData/ML_PROLONG/Test/LeftHand_NO_FLIP\n",
      "Normalization starting\n"
     ]
    }
   ],
   "source": [
    "#NORMALIZE AS NEEDED\n",
    "#normalize right hand and original lefthand data (without flip) together-----------------------------------------\n",
    "norm_path ='../NORMALIZED_ORIGINAL'\n",
    "crossValidationDataPaths=['../NumericalData/ML/Training/RightHand','../NumericalData/ML/Training/LeftHand_NO_FLIP']\n",
    "testPaths=['../NumericalData/ML/Test/RightHand','../NumericalData/ML/Test/LeftHand_NO_FLIP']\n",
    "print('normalize')\n",
    "normalizeData(norm_path,crossValidationDataPaths,testPaths)\n",
    "# DO THE SAME ON THE PROLONGED DATA NEEDED FOR SVM EXPERIMENTING ON ORIGINAL DATA (NO FLIP)\n",
    "norm_path ='../NORMALIZED_ORIGINAL'\n",
    "crossValidationDataPaths=['../NumericalData/ML_PROLONG/Training/RightHand','../NumericalData/ML_PROLONG/Training/LeftHand_NO_FLIP']\n",
    "testPaths=['../NumericalData/ML_PROLONG/Test/RightHand','../NumericalData/ML_PROLONG/Test/LeftHand_NO_FLIP']\n",
    "print('normalize')\n",
    "normalizeData(norm_path,crossValidationDataPaths,testPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "training path:  ../NumericalData/ML_PROLONG/Training/RightHand\n",
      "training path:  ../NumericalData/ML_PROLONG/Training/LeftHand\n",
      "test path:  ../NumericalData/ML_PROLONG/Test/RightHand\n",
      "test path:  ../NumericalData/ML_PROLONG/Test/LeftHand\n",
      "Normalization starting\n",
      "hello\n",
      "training path:  ../NumericalData/ML_PROLONG/Training/LeftHand_NO_FLIP\n",
      "test path:  ../NumericalData/ML_PROLONG/Test/LeftHand_NO_FLIP\n",
      "Normalization starting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#normalize right hand and lefthand flipped data together-----------------------------------------\n",
    "norm_path ='../NORMALIZED'\n",
    "crossValidationDataPaths=['../NumericalData/ML/Training/RightHand','../NumericalData/ML/Training/LeftHand']\n",
    "testPaths=['../NumericalData/ML/Test/RightHand','../NumericalData/ML/Test/LeftHand']\n",
    "normalizeData(norm_path,crossValidationDataPaths,testPaths)\n",
    "\n",
    "\n",
    "#normalize left hand (not flipped) data if someone want to experiment with the left hand original data only\n",
    "norm_path ='../NORMALIZED'\n",
    "crossValidationDataPaths=['../NumericalData/ML/Training/LeftHand_NO_FLIP']\n",
    "testPaths=['../NumericalData/ML/Test/LeftHand_NO_FLIP']\n",
    "normalizeData(norm_path,crossValidationDataPaths,testPaths)\n",
    "\n",
    "\n",
    "#normalize the prolonged data  --------------------------\n",
    "\n",
    "norm_path ='../NORMALIZED'\n",
    "crossValidationDataPaths=['../NumericalData/ML_PROLONG/Training/RightHand','../NumericalData/ML_PROLONG/Training/LeftHand']\n",
    "testPaths=['../NumericalData/ML_PROLONG/Test/RightHand','../NumericalData/ML_PROLONG/Test/LeftHand']\n",
    "normalizeData(norm_path,crossValidationDataPaths,testPaths)\n",
    "\n",
    "#normalize prolonged lefthand (not flipped) orignal data in case someone want to work with lefthand original data only------\n",
    "norm_path ='../NORMALIZED'\n",
    "crossValidationDataPaths=['../NumericalData/ML_PROLONG/Training/LeftHand_NO_FLIP']\n",
    "testPaths=['../NumericalData/ML_PROLONG/Test/LeftHand_NO_FLIP']\n",
    "normalizeData(norm_path,crossValidationDataPaths,testPaths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "training path:  ../DTW/Training/RightHand\n",
      "training path:  ../DTW/Training/LeftHand\n",
      "test path:  ../DTW/Test/RightHand\n",
      "test path:  ../DTW/Test/LeftHand\n",
      "Normalization starting\n"
     ]
    }
   ],
   "source": [
    "#DTW DISTANCES normalize right hand and lefthand flipped data together-----------------------------------------\n",
    "\n",
    "DTW_weights_available =False\n",
    "# DTW_weights_available =True\n",
    "\n",
    "if DTW_weights_available == False:\n",
    "    print ('KAGGLE DATASET NAME: DTW_BdSLW60')\n",
    "    print ('WARNING: DOWNLOAD THE PRECALCULATED DTW DISTANCE DATASET FROM KAGGLE FIRST')\n",
    "    print ('COPY THE DOWNLOADED DTW FOLDER IN THE PARENT DIRECTORY. YOU MAY SEE AND EMPTY DTW FOLDER THERE, OVERWRITE')\n",
    "    \n",
    "    print ('set DTW_weights_available flag to True')\n",
    "else :\n",
    "    norm_path ='../DTW_NORMALIZED'\n",
    "    crossValidationDataPaths=['../DTW/Training/RightHand','../DTW/Training/LeftHand']\n",
    "    testPaths=['../DTW/Test/RightHand','../DTW/Test/LeftHand']\n",
    "    normalizeData(norm_path,crossValidationDataPaths,testPaths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
