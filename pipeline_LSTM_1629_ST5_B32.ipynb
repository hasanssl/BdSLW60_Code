{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install tensorflow\n",
    "#!pip install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# crossValidationDataPaths=['NORMALIZED/NumericalData/ML/Training/RightHand','NORMALIZED/NumericalData/ML/Training/LeftHand']\n",
    "# testPaths=['NORMALIZED/NumericalData/ML/Test/RightHand','NORMALIZED/NumericalData/ML/Test/LeftHand']\n",
    "\n",
    "crossValidationDataPaths=['NORMALIZED_ORIGINAL/NumericalData/ML/Training/RightHand','NORMALIZED_ORIGINAL/NumericalData/ML/Training/LeftHand_NO_FLIP']\n",
    "testPaths=['NORMALIZED_ORIGINAL/NumericalData/ML/Test/RightHand','NORMALIZED_ORIGINAL/NumericalData/ML/Test/LeftHand_NO_FLIP']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ml_instances_paths=[]\n",
    "for path in crossValidationDataPaths:\n",
    "    #print(path)\n",
    "    classFolders= os.listdir(path)\n",
    "    for classFolder in classFolders:\n",
    "        classFolder_path=f'{path}/{classFolder}'\n",
    "        classTrials =os.listdir(classFolder_path)\n",
    "        for trial in classTrials:\n",
    "            trialPath =f'{classFolder_path}/{trial}'\n",
    "            #print(trialPath)\n",
    "            ml_instances_paths.append(trialPath)\n",
    "            \n",
    "\n",
    "\n",
    "#randomize the list\n",
    "random.shuffle(ml_instances_paths)\n",
    "\n",
    "\n",
    "\n",
    "x_shape =[]\n",
    "y_shape =[]\n",
    "for ml_instances_path in ml_instances_paths:\n",
    "    label = ml_instances_path.split('/')\n",
    "    label = label[len(label)-1].split('_')[0]\n",
    "    #print(label)\n",
    "    y_shape.append(int(label))\n",
    "    npy =np.load(ml_instances_path)\n",
    "    npy = npy*100\n",
    "  \n",
    "    npy_matrix=npy.reshape(-1,1629)\n",
    "   \n",
    "    # npy_matrix=extractPoseHand(npy)\n",
    "    x_shape.append(npy_matrix)    \n",
    "\n",
    "test_instances_paths=[]\n",
    "for path in testPaths:\n",
    "    #print(path)\n",
    "    testFolders= os.listdir(path)\n",
    "    for testFolder in testFolders:\n",
    "        testFolder_path=f'{path}/{testFolder}'\n",
    "        testTrials =os.listdir(testFolder_path)\n",
    "        for trial in testTrials:\n",
    "            trialPath =f'{testFolder_path}/{trial}'\n",
    "            #print(trialPath)\n",
    "            test_instances_paths.append(trialPath)\n",
    "\n",
    "\n",
    "test_x_shape =[]\n",
    "test_y_shape =[]\n",
    "for test_instances_path in test_instances_paths:\n",
    "    label = test_instances_path.split('/')\n",
    "    label = label[len(label)-1].split('_')[0]\n",
    "    #print(label)\n",
    "    test_y_shape.append(int(label))\n",
    "    npy =np.load(test_instances_path)\n",
    "    npy=npy*100\n",
    "    npy_matrix=npy.reshape(-1,1629)\n",
    "\n",
    "    # npy_matrix=extractPoseHand(npy)\n",
    "    \n",
    "    test_x_shape.append(npy_matrix)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_shape.shape)\n",
    "# print(y_shape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_x_shape.shape)\n",
    "# print(test_y_shape.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the total data\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Flatten, Dense,Input,  Dropout, BatchNormalization, GRU, Attention,Concatenate, Conv1D, Masking, Embedding\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 32 # 64\n",
    "NO_CLASSES = 60 #Changes according to no of class\n",
    "MAX_FRMAE = 164\n",
    "\n",
    "learning_rate = 0.00003\n",
    "input_shape = (MAX_FRMAE,1629)\n",
    "\n",
    "\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# print(y_shape)\n",
    "#y_onehot = to_categorical(y_shape).astype(int)\n",
    "label_encoder=LabelEncoder()\n",
    "y_encoded =label_encoder.fit_transform(y_shape)\n",
    "y_onehot =to_categorical(y_encoded,num_classes=NO_CLASSES)\n",
    "print(len(y_onehot))\n",
    "\n",
    "\n",
    "\n",
    "all_accuracies = []\n",
    "x_shapeML = np.array(x_shape) #.astype(int)\n",
    "x_train=x_shapeML\n",
    "y_train =y_onehot\n",
    "\n",
    "test_x_shapeML = np.array(test_x_shape) #.astype(int)\n",
    "x_val=test_x_shapeML\n",
    "\n",
    "#y_val = to_categorical(test_y_shape).astype(int)\n",
    "y_encoded =label_encoder.fit_transform(test_y_shape)\n",
    "y_val =to_categorical(y_encoded,num_classes=NO_CLASSES)\n",
    "\n",
    "\n",
    "print('Train shape: ',x_train.shape, y_train.shape,'Test Shape: ', x_val.shape, y_val.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train with total data and test with testt datta\n",
    "\n",
    "# input = Input(shape=input_shape)\n",
    "# bd1 = Bidirectional(LSTM(units=64, return_sequences=True))(input)\n",
    "\n",
    "# bd11 = Dropout(0.3)(bd1)\n",
    "# bd2 = Bidirectional(LSTM(units=64, return_sequences=True))(input)\n",
    "# att = Attention(use_scale=True)([bd2, bd11])\n",
    "# merged = Concatenate(axis=-1)([bd2, att])\n",
    "# flat = Flatten()(merged)\n",
    "# dense = Dense(units=64, activation='silu')(flat)\n",
    "# dp2 = Dropout(0.3)(dense)\n",
    "# out = Dense(NO_CLASSES, activation='softmax')(dp2)\n",
    " \n",
    "# model = Model(input, out)\n",
    "# optimizer = Adam(learning_rate=learning_rate)\n",
    "# early_stoppage = EarlyStopping(monitor=\"loss\",mode=\"auto\", patience = 5,  restore_best_weights=True)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=epochs,  batch_size=batch_size, callbacks=[early_stoppage])\n",
    "\n",
    "# y_val_pred = model.predict(x_val)\n",
    "# y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "# y_val_true_classes = np.argmax(y_val, axis=1)\n",
    "# test_accuracy = accuracy_score(y_val_true_classes, y_val_pred_classes)\n",
    "\n",
    "# conf_mat = confusion_matrix(y_val_true_classes,y_val_pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# print(test_accuracy)\n",
    "# ylabel =['W1','W2','W3','W4','W5','W6','W7','W8','W9','W10','W11','W12','W19','W20','W37','W38','W39','W40','W41','W42','W43','W44','W45','W46','W47','W48','W49','W50','W91','W92','W93','W94','W95','W96','W97','W98','W99','W100','W111','W112','W211','W212','W213','W214','W215','W216','W217','W218','W219','W220','W351','W352','W353','W354','W355','W356','W357','W358','W359','W360']\n",
    "# print(len(ylabel))\n",
    "# # ticklabels=np.unique(y_val_true_classes)\n",
    "# plt.figure(figsize=(12,10))\n",
    "# sns.heatmap(conf_mat, annot=True, fmt='d',cmap='Blues',xticklabels=ylabel,yticklabels=ylabel)\n",
    "# plt.title(f'confusion matrix for Test Accuracy: {test_accuracy}')\n",
    "# plt.xlabel('predicted')\n",
    "# plt.ylabel('actual')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_folds = 10\n",
    "# Train the model\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "\n",
    "i = 1\n",
    "\n",
    "all_accuracies = []\n",
    "test_accuracies = []\n",
    "conf_matrixes = []\n",
    "bestTestAccuracy=0\n",
    "bestTest=0\n",
    "\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "\n",
    "    input = Input(shape=input_shape)\n",
    "    bd1 = Bidirectional(LSTM(units=64, return_sequences=True))(input)\n",
    "    # bn1 = BatchNormalization()(bd1)\n",
    "    bd11 = Dropout(0.3)(bd1)\n",
    "\n",
    "    bd2 = Bidirectional(LSTM(units=64, return_sequences=True))(input)\n",
    "    # bd22 = BatchNormalization()(bd2)\n",
    "\n",
    "    att = Attention(use_scale=True)([bd2, bd11])\n",
    "\n",
    "    merged = Concatenate(axis=-1)([bd2, att])\n",
    "\n",
    "    flat = Flatten()(merged)\n",
    "    dense = Dense(units=64, activation='silu')(flat)\n",
    "    dp2 = Dropout(0.3)(dense)\n",
    "    out = Dense(NO_CLASSES, activation='softmax')(dp2)\n",
    "    \n",
    "    model = Model(input, out)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    early_stoppage = EarlyStopping(monitor=\"loss\",mode=\"auto\", patience = 5,  restore_best_weights=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    print(\"---------------fold {} -----------\".format(i))\n",
    "    \n",
    "    model.fit(x_train[train], y_train[train], epochs=epochs,  batch_size=batch_size, callbacks=[early_stoppage],validation_data=(x_train[test],y_train[test]))\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_val_pred = model.predict(x_train[test])\n",
    "    y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "    y_val_true_classes = np.argmax(y_train[test], axis=1)\n",
    "\n",
    "        # Calculate accuracy for the fold\n",
    "    test_accuracy = accuracy_score(y_val_true_classes, y_val_pred_classes)\n",
    "    # all_accuracies.append(test_accuracy)\n",
    "    all_accuracies.append(test_accuracy)\n",
    "    # average_accuracy = np.mean(all_accuracies)\n",
    "\n",
    "\n",
    "    ##avg_acc = all_accuracies/epochs\n",
    "\n",
    "    print(f'Validation Accuracy Fold {i}: {test_accuracy}')\n",
    "\n",
    "\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "    y_val_true_classes = np.argmax(y_val, axis=1)\n",
    "    test_accuracy = accuracy_score(y_val_true_classes, y_val_pred_classes)\n",
    "    if test_accuracy >bestTestAccuracy:\n",
    "        bestTestAccuracy=test_accuracy\n",
    "        bestTest=i\n",
    "    print(f'Test - Accuracy: {test_accuracy}')\n",
    "\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    conf_mat = confusion_matrix(y_val_true_classes,y_val_pred_classes)\n",
    "\n",
    "    conf_matrixes.append(conf_mat)\n",
    "    i += 1\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "average_accuracy = np.mean(all_accuracies)\n",
    "print(\"Average  cross validation accuracy: {average_accuracy}\")\n",
    "\n",
    "\n",
    "\n",
    "average_accuracy = np.mean(test_accuracies)\n",
    "print(\"Average test accuracy: {average_accuracy}\")\n",
    "\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# y_val_pred = model.predict(x_val)\n",
    "# y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "# y_val_true_classes = np.argmax(y_val, axis=1)\n",
    "# test_accuracy = accuracy_score(y_val_true_classes, y_val_pred_classes)\n",
    "# print(f'Test - Accuracy: {test_accuracy}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracies)\n",
    "print(np.average(test_accuracies))\n",
    "print(all_accuracies)\n",
    "print(np.average(all_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conf_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_conf_mat = np.sum(conf_matrixes, axis=0)\n",
    "# average_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conf_mat= conf_matrixes[bestTest-1]\n",
    "print('test accuracies: ',test_accuracies, 'best:', bestTest-1)\n",
    "# print ('validation accuracies: ',all_accuracies)\n",
    "# average_conf_mat = np.mean(conf_matrixes, axis=0)\n",
    "# for conf_matrix in conf_matrixes:\n",
    "#     average_conf_mat +=  conf_matrix\n",
    "# y_val_true_classes,y_val_pred_classes\n",
    "ylabel =['W1','W2','W3','W4','W5','W6','W7','W8','W9','W10','W11','W12','W19','W20','W37','W38','W39','W40','W41','W42','W43','W44','W45','W46','W47','W48','W49','W50','W91','W92','W93','W94','W95','W96','W97','W98','W99','W100','W111','W112','W211','W212','W213','W214','W215','W216','W217','W218','W219','W220','W351','W352','W353','W354','W355','W356','W357','W358','W359','W360']\n",
    "print(len(ylabel))\n",
    "# ticklabels=np.unique(y_val_true_classes)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',cmap='Blues',xticklabels=ylabel,yticklabels=ylabel)\n",
    "plt.title(f'confusion matrix for Test data in fold #{bestTest} Accuracy: {test_accuracies[bestTest-1]}')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(f'HandPose_RightHand_LeftHandFlipped_acc_{bestTest-1}_{test_accuracies[bestTest-1]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_val_pred.shape)\n",
    "# print(y_val_pred)\n",
    "# print(y_val_pred[0][10])\n",
    "\n",
    "# bestTest-1\n",
    "\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val_pred = model.predict(x_val)\n",
    "# print(y_val_pred[0])\n",
    "# y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "# y_val_true_classes = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
